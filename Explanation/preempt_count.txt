preempt_count()

In a multitasking system like Linux, 
no thread of execution is guaranteed exclusive access to the processor for as long as it would like to run; 
the kernel can (almost) always preempt a running thread in favor of one that has a higher priority. 
That new thread might be a different process, but it might also be a hardware interrupt or other outside event. 
In order to properly coordinate the running of all of a system's tasks, the kernel must keep track of the current execution state, 
including anything that has been preempted or which might prevent a thread from being preempted.

One piece of the infrastructure for that tracking is the preemption counter that is stored with every task in the system. 
That counter is accessed via the preempt_count() function which, in its generic form, looks like this:

    static __always_inline int preempt_count(void)
    {
	return READ_ONCE(current_thread_info()->preempt_count);
    }

The purpose of this counter is to describe the current state of whatever thread has been running, 
whether it can be preempted, and whether it is allowed to sleep. 
To do so, it must track a number of different states, so it is split into several sub-fields:

    MSBit   -> Reschedule needed
    Field 3 -> Non-maskable interrupt count
    Field 2 -> Hardware interrupt count
    Field 1 -> Software interrupt count
    LSByte  -> Preempt-disable count

The least-significant byte tracks the nesting of preempt_disable() calls — the number of times that preemption has been disabled so far. 
The next three fields track the number of times the running thread has been interrupted by software, hardware, 
and non-maskable interrupts; 
they are all probably oversized for the number of interruptions that is likely to ever happen in real execution, 
but bits are not in short supply here. 
Finally, the most-significant bit indicates whether the kernel has decided that the current process needs to 
be scheduled out at the first opportunity.

A look at this value tells the kernel a fair amount about what is going on at any given time. 
For example, any non-zero value for preempt_count indicates that the current thread cannot be preempted by the scheduler; 
either preemption has been disabled explicitly or the CPU is currently servicing some sort of interrupt. 
In the same way, a non-zero value indicates that the current thread cannot sleep, 
since it is running in a context that must be allowed to run to completion. 
The "reschedule needed" bit tells the kernel that there is a higher-priority process 
that should be given the CPU at the first opportunity. 
This bit cannot be set unless preempt_count is non-zero; 
otherwise the kernel would have simply preempted the process rather than setting the bit and waiting.

Code throughout the kernel uses preempt_count to make decisions about which actions are possible at any given time. 
That, as it turns out, can be a bit of a problem for a few reasons.

> Misleading counts
It is worth noting that preempt_disable() only applies when a thread is running within the kernel; 
user-space code is always preemptible. 
In the distant past, the kernel did not support preemption of kernel-space code at all; 
when that feature was added (as a way of improving latency), it was also made configurable. 
There are, as a result, still systems out there that are running without kernel preemption at all; 
it is a configuration that might make sense for some throughput-oriented workloads.

If kernel code cannot be preempted, there is little value in tracking calls to preempt_disable(); preemption is always disabled. 
So the kernel doesn't waste its time maintaining that information; 
in such kernels, the preempt-disable count portion of preempt_count is always zero. 
The preemptible() function will always return false, since the kernel is indeed not preemptible. 
It all seems to make sense.

There are some problems that result from this behavior, though. 
One is that functions like in_atomic(), which indicates whether the kernel is currently running in atomic context, 
do not behave in the same way. 
On a kernel with preemption configured in, calling preempt_disable() will cause in_atomic() to return true; 
if preemption is configured out, preempt_disable() is a no-op and in_atomic() will return false. 
This can cause in_atomic() to return false when, for example, spinlocks are held — a situation that is indeed an atomic context.

Gleixner, in his patch set, 
points out some other problems that result from this inconsistency and says that it is a problem overall:

    The lack of such indicators which work on all kernel configurations is a constant source of trouble 
    because developers either do not understand the implications or try to work around this inconsistency in weird ways.

His solution is to remove the conditional compilation for the preemption-disable tracking, 
causing that counter to be maintained even in kernels that do not support kernel preemption. 
There is a cost in terms of increased execution time and code size on machines running those configurations, 
but Gleixner says that his benchmark testing "did not reveal any measurable impact" from the change.

Linus Torvalds was not convinced about the value of this change, noting
that the code generation for spinlocks is indeed better when preemption is not possible. 
Gleixner reiterated that the effect is not measurable, 
and Torvalds conceded that the patch set does make the code simpler and "has its very clear charm".

To an extent, there is general agreement with this position. 
Gleixner's patch posting included a section with future plans to audit and fix callers of functions like in_atomic() where, 
he says, "the number of buggy users is clearly the vast majority". 
Daniel Vetter added that, in his experience, 
"code that tries to cleverly adjust its behaviour depending upon the context 
it's running in is harder to understand and blows up in more interesting ways".

Paul McKenney, instead, argued that some code has to be able to operate properly in different contexts; 
the alternative would be an explosion of the API:

    Now perhaps you like the idea of call_rcu() for schedulable contexts, call_rcu_nosched() when preemption is disabled, 
    call_rcu_irqs_are_disabled() when interrupts are disabled, 
    call_rcu_raw_atomic() from contexts where (for example) raw spinlocks are held, and so on. 
    However, from what I can see, most people instead consistently prefer that the RCU API instead be consolidated.

In response, Torvalds clarified that he sees core-kernel code as having different requirements than the rest. 
Core code has to deal with multiple contexts and should always do the right thing; 
code in drivers, instead, should not be changing its behavior based on its view of the context.

> Questioning high memory
One example of questionable use of preempt_count, in the crypto code, was pointed out early in the discussion by Gleixner; 
it changes a memory allocation mode in strange ways if it thinks that it's not currently preemptible. 
After some discussion, it turned out, according to Ard Biesheuvel, 
that the real purpose had been to avoid using kmap_atomic() if possible.

For those who are not immediately familiar with kmap_atomic(), a look at this article on high memory might be helpful. 
In short: 32-bit machines can only map a limited amount of memory into the kernel's address space; 
that amount is a little under 1GB on most architectures and configurations. 
Any memory that is not directly mapped is deemed "high memory"; 
any page in high memory must be explicitly (and temporarily) mapped into the kernel before the kernel can access its contents. 
The functions kmap() and kmap_atomic() exist to perform this mapping.

There are a few differences between those two functions, 
starting with the fact that only kmap_atomic() is callable in atomic context. 
Beyond that, though, kmap_atomic() is more efficient and is thus seen as being strongly preferable in any situation 
where it can be used, regardless of whether the caller was running in atomic context before 
the call (the CPU will always be running in atomic context while the mapping is in place). 
As Biesheuvel pointed out, though, the documentation doesn't reflect this preference and encourages the use of kmap() instead, 
so that is what he did.

There is another reason to prefer kmap(), he added; 
a call to kmap_atomic() disables preemption even on 64-bit architectures, 
where high memory does not exist and no temporary mapping need be made. 
Using it would have resulted in much of the WireGuard VPN code running with preemption disabled, entirely unnecessarily. 
Torvalds pointed out that there is a reason for this behavior: 
it is there to cause code to fail on 64-bit machines if it does things that would not work on 32-bit machines 
where high memory does exist. 
It is essentially a debugging aid that is making up for the fact that few developers run on 32-bit machines.

One way to optimize kmap_atomic() on 64-bit systems, Gleixner said, 
would be to make kmap_atomic() sections be preemptible — no longer atomic, in other words. 
This approach has been taken in the realtime kernels, he said, and "it's not that horrible". 
The cost would be to make kmap_atomic() a little slower on systems where high memory is in use.

That, it seems, is a cost that the development community is increasingly willing to pay; 
Torvalds replied that he would like to start removing kmap() support entirely. 
32-Bit systems will be around for some time yet, but they are increasingly unlikely to be used in situations 
where lots of memory is needed. Or, as Torvalds put it: "It's not that 32-bit is irrelevant, 
it's that 32-bit with large amounts of memory is irrelevant". 
Every time that the cost of supporting high memory 
(which adds a significant amount of complexity to the memory-management subsystem) makes itself felt, 
the desire to take it out grows.

That said, nobody will be removing high-memory support right away. 
But a change that penalizes high-memory systems in favor of the systems that are being deployed now, 
such as making kmap_atomic() no longer be atomic, is increasingly likely to be accepted. 
Meanwhile, the other issues around preempt_count remain mostly unresolved, but it seems likely that,
in the end, changes that bring correctness and reduce complexity will probably win out.

Summary:
(當 process 進入執行狀態（running state）時，排程器（scheduler）會去檢查進入該 process 優先序（priority），
若該 process 的 priority 比目前執行中的 process priority 高，Linux 便會搶先（preemptive）執行該 process，
因此原本的 process 便被中斷（interrupt）。)

在多工系統中，thread執行有可能被搶先執行，preempt_count是用來記錄thread目前執行的狀態。像是能不能被搶先執行，或是能不能sleep。
這個count切分為5個部分，最右邊的第一個Byte表示禁用對這個thread搶先執行的次數，
接下來三個部分分別追蹤這個thread被software, hardware, non-maskable interrupt中斷的次數，
最左邊的位元則是表示Kernel是否決定之後一有機會就要把這個thread中斷執行，重新排程。
當preempt_count不為0時，代表目前這個thread不能被搶先執行或sleep，可能是禁用了對它的搶先執行，或是CPU正在處理中斷，
是需要執行到結束的狀態。
最左邊的rescheduled needed位元，會讓Kernel知道外面有個更高優先度的process在等待，
這個位元只有在preempt_count不為0(目前這個thread不能被搶先執行或sleep)時能夠設定，
不然Kernel就不會等待，而是直接中斷目前的thread。
preempt_disable只有在thread跑在kernel時有效，user-space永遠是搶先執行的。
在kernel，搶先執行這個行為是能夠被設定是否開啟的。




